{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNHxGp9ejbKCVdnTJiUYGjE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ab6a7d179cf946cd80d35596ddbf35cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a395ff612690480da542d37940361a87","IPY_MODEL_7ce5f1030dcc42488d35aeb9b270a7f9","IPY_MODEL_5ba4c8e3ef854a9eb3cdb253231e76e3"],"layout":"IPY_MODEL_a6509c7a29c1440d94bba1f9fe04042f"}},"a395ff612690480da542d37940361a87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a7095c6568f4f6cb49460eb9428bf6f","placeholder":"​","style":"IPY_MODEL_a99bc7c84af2487c9ec190aa5eb11592","value":"100%"}},"7ce5f1030dcc42488d35aeb9b270a7f9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e301d44867e40c5827e2b3928114118","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_88a784c726c846f99b247916a7ff9366","value":50}},"5ba4c8e3ef854a9eb3cdb253231e76e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa0f1cf110a34fd784f6feed2521e7fd","placeholder":"​","style":"IPY_MODEL_3e92d413b9f44f8ebc982d4e2b0192af","value":" 50/50 [00:00&lt;00:00, 66.22it/s]"}},"a6509c7a29c1440d94bba1f9fe04042f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a7095c6568f4f6cb49460eb9428bf6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a99bc7c84af2487c9ec190aa5eb11592":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e301d44867e40c5827e2b3928114118":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88a784c726c846f99b247916a7ff9366":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa0f1cf110a34fd784f6feed2521e7fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e92d413b9f44f8ebc982d4e2b0192af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install implicit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OTYtntDHmiX8","executionInfo":{"status":"ok","timestamp":1746863789420,"user_tz":-180,"elapsed":5034,"user":{"displayName":"Шамиль","userId":"15878585847189737223"}},"outputId":"f1f768e1-0a55-4d7d-accc-bbdbef0ebbca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: implicit in /usr/local/lib/python3.11/dist-packages (0.7.2)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from implicit) (2.0.2)\n","Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.11/dist-packages (from implicit) (1.15.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from implicit) (4.67.1)\n","Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from implicit) (3.6.0)\n"]}]},{"cell_type":"markdown","source":["В данном датасете имеется файл rating_final.csv с данными по посетителю, ресторану и рейтингу, который он ему поставил. Таким образом, мы можем решить задачу рекомендации. Эти данные можно использовать для коллаборативной фильтрации. Я выбрал метод ALS из-за его скорости и эффективности работы с разреженными матрицами.\n","\n","Имеются также различные данные, связанные с особенностями ресторанов и посетителей. Их можно использовать для content-based рекомендации.\n","\n","В реальности, особенно в случае работы с большими данными, переобучать модель при каждом изменении матрицы взаимодействий является слишком затратной операцией, поэтому я решил использовать двухэтапную модель ALS + lightgbm.\n","\n","Тут ALS выступает в роли модели, которая занимается выдачей заданного числа кандидатов на основе оценок пользователей и ресторанов с оценками.\n","\n","lightgbm же уже ранжирует их, используя content-фичи из остальных файлов. Его можно переобучать чаще, чем ALS"],"metadata":{"id":"EewPIidCyhxE"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import OneHotEncoder\n","from scipy.sparse import csr_matrix\n","from implicit.als import AlternatingLeastSquares\n","from collections import defaultdict\n","import lightgbm as lgb\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import ndcg_score"],"metadata":{"id":"rPsK0B-ogqOm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IS_EVALUATING = True # Флаг, необходимый для вывода метрик"],"metadata":{"id":"IZb0aHORjnfo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Загружаю данные по явным оценкам и строю матрицу взаимодействий."],"metadata":{"id":"E3mpL31N07E5"}},{"cell_type":"code","source":["def load_data_ALS():\n","    ratings = pd.read_csv(\"rating_final.csv\")\n","\n","    # Преобразование userID и placeID в индексы для ALS\n","    user_ids = ratings['userID'].unique()\n","    user_to_index = {user: idx for idx, user in enumerate(user_ids)}\n","    place_ids = ratings['placeID'].unique()\n","    place_to_index = {place: idx for idx, place in enumerate(place_ids)}\n","\n","    # Создание матрицы взаимодействий\n","    ratings['user_index'] = ratings['userID'].map(user_to_index)\n","    ratings['place_index'] = ratings['placeID'].map(place_to_index)\n","    ratings_matrix = csr_matrix(\n","        (ratings['rating'], (ratings['user_index'], ratings['place_index'])),\n","        shape=(len(user_ids), len(place_ids))\n","    )\n","\n","    return ratings_matrix, user_to_index, place_to_index, ratings\n"],"metadata":{"id":"69e_jOJaqPKQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ratings_matrix, user_to_index, place_to_index, ratings = load_data_ALS()"],"metadata":{"id":"0fWwd_Vv5wJ0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Обучаю модель ALS, которую можно сохранить для дальнейших взаимодействий"],"metadata":{"id":"tJMhS8MV58ON"}},{"cell_type":"code","source":["model = AlternatingLeastSquares(factors=50, iterations=50)\n","model.fit(ratings_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["ab6a7d179cf946cd80d35596ddbf35cb","a395ff612690480da542d37940361a87","7ce5f1030dcc42488d35aeb9b270a7f9","5ba4c8e3ef854a9eb3cdb253231e76e3","a6509c7a29c1440d94bba1f9fe04042f","0a7095c6568f4f6cb49460eb9428bf6f","a99bc7c84af2487c9ec190aa5eb11592","3e301d44867e40c5827e2b3928114118","88a784c726c846f99b247916a7ff9366","fa0f1cf110a34fd784f6feed2521e7fd","3e92d413b9f44f8ebc982d4e2b0192af"]},"id":"XFbeztg6228-","executionInfo":{"status":"ok","timestamp":1746863790584,"user_tz":-180,"elapsed":1046,"user":{"displayName":"Шамиль","userId":"15878585847189737223"}},"outputId":"ae7fe62d-4f71-4dab-9b6a-72b93122fba8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab6a7d179cf946cd80d35596ddbf35cb"}},"metadata":{}}]},{"cell_type":"markdown","source":["Определяю функцию генерации кандидатов"],"metadata":{"id":"7XgGzBeE0-xm"}},{"cell_type":"code","source":["def generate_candidates(model, ratings_matrix, user_to_index, place_to_index, ratings, is_evaluating : bool):\n","    # Генерация кандидатов\n","    candidates = []\n","    user_ids = list(user_to_index.keys())\n","    place_ids = list(place_to_index.keys())\n","\n","    for user_id in user_ids:\n","        user_index = user_to_index[user_id]\n","        rated_places = ratings[ratings['userID'] == user_id]['placeID'].unique()\n","        all_places = set(place_ids)\n","        if not is_evaluating:\n","          all_places = list(all_places - set(rated_places))\n","\n","        place_indices = [place_to_index[p] for p in all_places]\n","        user_vector = model.user_factors[user_index]\n","        place_vectors = model.item_factors[place_indices]\n","        scores = np.dot(place_vectors, user_vector)\n","\n","        for place_id, score in zip(all_places, scores):\n","            candidates.append({\n","                'userID': user_id,\n","                'placeID': place_id,\n","                'predicted_rating': score\n","            })\n","\n","    return pd.DataFrame(candidates)"],"metadata":{"id":"3vtKGUQr7diP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Генерирую датасет с кандидатами (посетитель, ресторан, предсказанный скор от ALS)"],"metadata":{"id":"7u9GH0Cp1T1u"}},{"cell_type":"code","source":["candidates_df = generate_candidates(model, ratings_matrix, user_to_index, place_to_index, ratings, IS_EVALUATING)"],"metadata":{"id":"kh7WxCufKyGq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Определяю функцию для отбора выбранного количества наиболее релевантных кандидатов из сгенерированного датасета."],"metadata":{"id":"XCACSV-d6YMv"}},{"cell_type":"code","source":["def get_top_candidates(user_id, n_top, candidates_df):\n","    # Фильтрация кандидатов по пользователю\n","    user_candidates = candidates_df[candidates_df['userID'] == user_id]\n","\n","    if user_candidates.empty:\n","        print(f\"Для пользователя {user_id} нет кандидатов.\")\n","        return pd.DataFrame()\n","\n","    # Сортировка и выбор топ-N\n","    result_df = user_candidates.sort_values('predicted_rating', ascending=False).head(n_top)\n","\n","    result_df = result_df.drop_duplicates(subset=['placeID'])\n","    return result_df"],"metadata":{"id":"VY6l3IfnqShJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Теперь приступаю к работе с content-based частью модели.\n","\n","Загружаю все датасеты, отбрасываю невалидные и мерджу их по общим ключам. В случае если, например, у посетителя несколько предпочтений по кухне, то создастся соответствующее количество записей с оценками, хотя на самом деле оценка могла быть лишь одна.\n","\n","Я пробовал группировать значения подобных признаков в списки и кодировать их при помощи Multi-Hot, однако в таком случае метрики значительно ухудшались, поэтому было принято решение оставить данные в таком виде."],"metadata":{"id":"iAbCelQQ6lwq"}},{"cell_type":"code","source":["def load_full_data():\n","    ratings = pd.read_csv(\"rating_final.csv\")\n","\n","    print(f\"Всего оценок: {len(ratings)}\")\n","    print(f\"Уникальных пользователей: {ratings['userID'].nunique()}\")\n","\n","    geoplaces = pd.read_csv(\"geoplaces2.csv\", encoding='latin1')\n","    userprofile = pd.read_csv(\"userprofile.csv\", encoding='latin1')\n","\n","    userprofile = userprofile[userprofile['userID'].notna()]\n","\n","    dfs = {\n","        'ratings': ratings,\n","        'geoplaces': geoplaces,\n","        'userprofile': userprofile,\n","        'usercuisine': pd.read_csv(\"usercuisine.csv\"),\n","        'userpayment': pd.read_csv(\"userpayment.csv\"),\n","        'chefmozcuisine': pd.read_csv(\"chefmozcuisine.csv\"),\n","        'chefmozparking': pd.read_csv(\"chefmozparking.csv\"),\n","        'chefmozaccepts': pd.read_csv(\"chefmozaccepts.csv\")\n","    }\n","\n","    full_data = dfs['ratings'].merge(\n","        dfs['geoplaces'], on='placeID', validate='many_to_one'\n","    ).merge(\n","        dfs['userprofile'], on='userID', validate='many_to_one'\n","    ).merge(\n","        dfs['usercuisine'], on='userID', suffixes=('', '_user')\n","    ).merge(\n","        dfs['userpayment'], on='userID'\n","    ).merge(\n","        dfs['chefmozcuisine'], on='placeID'\n","    ).merge(\n","        dfs['chefmozparking'], on='placeID'\n","    ).merge(\n","        dfs['chefmozaccepts'], on='placeID'\n","    )\n","\n","    full_data['Rpayment'] = full_data['Rpayment'].fillna('unknown')\n","    return full_data"],"metadata":{"id":"CMw8l3JRMAnC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["На этапе FE удаляю ненужные фичи(адрес, зип-код, url, fax и т.д.), а также те, которые значительно снижали метрики или никак не них не влияли.\n","\n","Также использую ordinal_encoder для признаков, которые явно можно сопоставить с числами и onehot_encoder для остальных."],"metadata":{"id":"hUQF9qWX75p-"}},{"cell_type":"code","source":["def feature_engineering(df):\n","    cols_to_drop = [\n","        'the_geom_meter_x', 'the_geom_meter_y', 'name', 'address',\n","        'city', 'state', 'country', 'fax', 'zip', 'url', 'placeID', 'Rcuisine_user', 'payment',\n","        'ratings', 'latitude', 'longitude', 'height', 'other_services'\n","    ]\n","    df = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors='ignore')\n","\n","    # Ordinal Encoding\n","    ordinal_map = {\n","        'price': {'low': 1, 'medium': 2, 'high': 3, None: 2},\n","        'budget': {'low': 1, 'medium': 2, 'high': 3, None: 2},\n","        'alcohol': {'No_Alcohol_Served': 0, 'Wine-Beer': 1, 'Full_Bar': 2, None: 0},\n","        'smoking_area': {'none': 0, 'permitted': 1, 'section': 2, 'only': 3, None: 0},\n","        'dress_code': {'informal': 0, 'casual': 1, 'formal': 2, None: 1}\n","    }\n","\n","    for col, mapping in ordinal_map.items():\n","        if col in df.columns:\n","            df[col] = df[col].map(mapping).fillna(0).astype('int8')\n","\n","    # One-Hot Encoding\n","    categorical_cols = [\n","        'Rpayment', 'main_cuisine', 'parking_lot', 'franchise',\n","        'area', 'Rambience', 'accessibility', 'transport'\n","    ]\n","    categorical_cols = [c for c in categorical_cols if c in df.columns]\n","    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True, dtype='int8')\n","\n","    if 'userID' in df.columns and df['userID'].dtype not in ['int64', 'float64']:\n","        user_ids = df['userID']  # Запоминаю userID, т.к. его выкинет после select_dtypes\n","\n","    # Фильтрация финальных признаков\n","    df = df.select_dtypes(include=['number'])\n","    df = df.loc[:, df.nunique() > 1]\n","\n","    df['userID'] = user_ids # Возвращаю обратно\n","\n","    return df"],"metadata":{"id":"YXDha8IdmGto"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Определяю функцию для тренировки модели. Перед этим была протестирована XGBoost, но метрики на ней были хуже, поэтому я остановился на lightbm.\n","Оптимизацию гиперпараметров не проводил, подобрал вручную. Стоит отметить, что в гиперпараметрах в \"objective\" стоит параметр \"lambdarank\", который при обучении модели минимизирует указанную метрику. В данном случае \"metric\": \"ndcg\". То есть модель обучается ранжировать, а не угадывать рейтинги, как было бы в случае \"regression\" и \"rmse\"."],"metadata":{"id":"4rr0Ntu3_0qa"}},{"cell_type":"code","source":["def train_lightgbm_model():\n","    full_data = load_full_data()\n","    processed_data = feature_engineering(full_data)\n","\n","    y = processed_data['rating']\n","    X = processed_data.drop(columns=['rating', 'food_rating', 'service_rating', 'userID'], errors='ignore') # Выкидываю явные признаки и userID\n","\n","    # Формирую group - количество элементов для каждого пользователя, нужны для lambdarank\n","    user_counts = processed_data['userID'].value_counts().sort_index()\n","    group = user_counts.tolist()\n","\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n","\n","    train_users = processed_data.loc[X_train.index, 'userID']\n","    train_group = train_users.value_counts().sort_index().tolist()\n","\n","    val_users = processed_data.loc[X_val.index, 'userID']\n","    val_group = val_users.value_counts().sort_index().tolist()\n","\n","    params = {\n","        \"objective\": \"lambdarank\",\n","        \"metric\": \"ndcg\",\n","        \"num_leaves\": 20,\n","        \"learning_rate\": 0.01,\n","        \"min_data_in_leaf\": 30,\n","        \"feature_fraction\": 0.9,\n","        \"verbosity\": -1\n","    }\n","\n","\n","    train_dataset = lgb.Dataset(X_train, label=y_train, group=train_group) # train с группами\n","    val_dataset = lgb.Dataset(X_val, label=y_val, group=val_group, reference=train_dataset) # Валидационный с группами для train-а\n","\n","    model = lgb.train(\n","        params,\n","        train_dataset,\n","        num_boost_round=1500,\n","        valid_sets=[val_dataset],\n","        callbacks=[lgb.early_stopping(50)]\n","    )\n","\n","    return model, X.columns.tolist(), X_val, y_val"],"metadata":{"id":"BT_kz9i3mHU9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Создаю функцию, чтобы достать нужные данные по полученным рекомендациям ALS (кандидаты). Также сразу обрабатываю NaN-ы и нормирую числовые признаки"],"metadata":{"id":"8x1qnpf7Czzv"}},{"cell_type":"code","source":["def fill_candidates(candidates):\n","    user_features = pd.read_csv(\"userprofile.csv\", encoding='latin1')\n","    place_features = pd.read_csv(\"geoplaces2.csv\", encoding='latin1')\n","\n","    filled = candidates.merge(\n","        user_features, on='userID', how='left', validate='many_to_one'\n","    ).merge(\n","        place_features, on='placeID', how='left', validate='many_to_one'\n","    )\n","\n","    # NaN-ы\n","    for col in ['price', 'budget']:\n","        if col in filled.columns:\n","            filled[col] = filled[col].fillna('medium')\n","\n","    if 'Rcuisine' in filled.columns:\n","        filled['main_cuisine'] = filled['Rcuisine'].fillna('other')\n","        filled = filled.drop(columns='Rcuisine')\n","\n","    numeric_cols = ['birth_year', 'weight']\n","    for col in numeric_cols:\n","        if col in filled.columns:\n","            filled[col] = filled[col].fillna(filled[col].median())\n","            filled[col] = (filled[col] - filled[col].mean()) / filled[col].std()\n","\n","    return filled"],"metadata":{"id":"vt5bDLZ6mffx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def check_data_integrity():\n","    geoplaces = pd.read_csv(\"geoplaces2.csv\", encoding='latin1')\n","    duplicates = geoplaces.duplicated('placeID').sum()\n","    if duplicates > 0:\n","        print(f\"Найдено {duplicates} дубликатов placeID. Исправление...\")\n","        geoplaces = geoplaces.drop_duplicates('placeID', keep='first')\n","        geoplaces.to_csv(\"geoplaces2.csv\", index=False)\n","    return geoplaces['placeID'].unique()"],"metadata":{"id":"Wed5kPPTmfVW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Определяю функции метрик. Сначала также определил NDCG, но скоры lambdarank это не рейтинги, а потому я не уверен, что их можно использовать для подсчета dcg, но даже так значение метрики было довольно высоко (ndcg@10 = 0.85 при 10 кандидатах, ndcg@10 = 0.6 при 30 кандидатах)"],"metadata":{"id":"R2BR38SOFc1h"}},{"cell_type":"code","source":["def precision_at_k(recommended, true_relevant, k):\n","    top_k = recommended[:k]\n","    relevant_in_top_k = len(set(top_k) & set(true_relevant))\n","    return relevant_in_top_k / k if k > 0 else 0\n","\n","def recall_at_k(recommended, true_relevant, k):\n","    top_k = recommended[:k]\n","    relevant_in_top_k = len(set(top_k) & set(true_relevant))\n","    return relevant_in_top_k / len(true_relevant)\n","\n","def average_precision_at_k(recommended, true_relevant, k):\n","    precisions = []\n","    relevant_count = 0\n","\n","    for i, item in enumerate(recommended[:k], 1):\n","        if item in true_relevant:\n","            relevant_count += 1\n","            precisions.append(relevant_count / i)\n","\n","    return sum(precisions) / len(true_relevant) if precisions else 0.0"],"metadata":{"id":"2DvzLiIjFcO-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def print_metrics(avg_metrics):\n","    print(f\"Оценено пользователей: {avg_metrics['users_processed']}\")\n","    print(f\"Precision@10: {avg_metrics['precision']:.4f}\")\n","    print(f\"Recall@10:    {avg_metrics['recall']:.4f}\")\n","    print(f\"MAP@10:       {avg_metrics['map']:.4f}\")"],"metadata":{"id":"uKMB1UTFGoqd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Определяю функцию для подсчета метрик, где в ней же генерирую рекомендации для всех пользователей. Далее усредняю значения метрик по всем посетителям."],"metadata":{"id":"1hRr7K2GD3rG"}},{"cell_type":"code","source":["def calculate_metrics_for_all_users(model, user_ids, k=10):\n","    ratings = pd.read_csv(\"rating_final.csv\")\n","    place_info = pd.read_csv(\"geoplaces2.csv\", encoding='latin1')\n","\n","    metrics = {\n","        'precision': [],\n","        'recall': [],\n","        'map': [],\n","        'users_processed': 0\n","    }\n","    user_metrics = {}\n","\n","    for user_id in user_ids:\n","        # Получаю истинные оценки пользователя\n","        user_ratings = (\n","            ratings[ratings['userID'] == user_id]\n","            .merge(place_info, on='placeID', how='left')\n","            .dropna(subset=['rating'])\n","            .sort_values('rating', ascending=False)\n","        )\n","\n","        true_relevant = user_ratings['placeID'].tolist()\n","        true_scores = user_ratings['rating'].values.astype(float)\n","\n","        # Генерация рекомендаций\n","        n_top = 10\n","        candidates = get_top_candidates(user_id, n_top, candidates_df)\n","        processed = feature_engineering(fill_candidates(candidates))\n","        processed = processed.reindex(columns=features, fill_value=0)\n","\n","        scores = model.predict(processed)\n","        candidates['score'] = scores\n","        recommended = candidates.nlargest(k, 'score')['placeID'].tolist()\n","\n","        # Расчёт метрик\n","        precision = precision_at_k(recommended, true_relevant, k)\n","        recall = recall_at_k(recommended, true_relevant, k)\n","        ap = average_precision_at_k(recommended, true_relevant, k)\n","\n","        # Сохранение результатов\n","        user_metrics[user_id] = {\n","            'precision': precision,\n","            'recall': recall,\n","            'map': ap,\n","            'true_items': true_relevant[:5],\n","            'recommended': recommended[:k]\n","        }\n","\n","        metrics['precision'].append(precision)\n","        metrics['recall'].append(recall)\n","        metrics['map'].append(ap)\n","        metrics['users_processed'] += 1\n","\n","\n","    # Усреднение метрик\n","    avg_metrics = {k: np.mean(v) if k != 'users_processed' else v\n","                  for k, v in metrics.items()}\n","\n","    print_metrics(avg_metrics)\n","\n","    return avg_metrics, user_metrics"],"metadata":{"id":"0iNZpYKNnAsp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Обучаю модель lightgbm на всех доступных данных."],"metadata":{"id":"Foe5Id3nHTpn"}},{"cell_type":"code","source":["# Обучение модели lightgbm\n","model, features, _, _ = train_lightgbm_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IAUbWmffHJ3H","executionInfo":{"status":"ok","timestamp":1746863793065,"user_tz":-180,"elapsed":1892,"user":{"displayName":"Шамиль","userId":"15878585847189737223"}},"outputId":"72f826e9-326f-47d8-d535-f8eba2c21561"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Всего оценок: 1161\n","Уникальных пользователей: 138\n","Training until validation scores don't improve for 50 rounds\n","Early stopping, best iteration is:\n","[1]\tvalid_0's ndcg@1: 0.982301\tvalid_0's ndcg@2: 0.985474\tvalid_0's ndcg@3: 0.985942\tvalid_0's ndcg@4: 0.986554\tvalid_0's ndcg@5: 0.986278\n"]}]},{"cell_type":"markdown","source":["Считаю и вывожу метрики"],"metadata":{"id":"AqD9oyGkHbhQ"}},{"cell_type":"code","source":["ratings = pd.read_csv(\"rating_final.csv\")\n","\n","user_ids_to_evaluate = ratings['userID'].unique()[:138] # Оцениваю по всем пользователям\n","\n","avg_metrics, user_metrics = calculate_metrics_for_all_users(\n","    model, user_ids_to_evaluate, k=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YDSWnE-Gf3hZ","executionInfo":{"status":"ok","timestamp":1746863810018,"user_tz":-180,"elapsed":16951,"user":{"displayName":"Шамиль","userId":"15878585847189737223"}},"outputId":"2a90037b-8e6c-4048-f88b-2b04bc672303"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-524-c24277f94eda>:37: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df['userID'] = user_ids # Возвращаю обратно\n"]},{"output_type":"stream","name":"stdout","text":["Оценено пользователей: 138\n","Precision@10: 0.7022\n","Recall@10:    0.8568\n","MAP@10:       0.8347\n"]}]},{"cell_type":"markdown","source":["Модель получает хорошие метрики от 10 до 30 кандидатов от ALS. Если бы данных было больше, то количество кандидатов можно было поднять."],"metadata":{"id":"PHkzlQK-MqNL"}}]}